Dilemma Description ,Expert Opinion
"I joined a lab during graduate school and was assigned to a post-doc, who immediately had me working
with him to synthesize a key compound for his project. We worked on the compound for a number of
months with him directing the effort. However, I was pleased with my own contributions and was
delighted to get positive feedback from him. Indeed, the overall experience I was having was very
positive, making me work even harder on the project.
That’s when things got interesting. Early one evening, when we felt we were very close to
success, I decided to stay a bit longer in the lab and try out some hunches. As I systematically tried out
each one and tested it to see if it was correct, I FINALLY GOT IT. I verified it over and over to make sure.
And I was overjoyed. I wrote it up, and left the lab in the wee hours of the morning elated but
exhausted.
So I didn’t get to the lab until late the next morning, but I wasn’t concerned because I knew my
senior partner would be gratified. What do I see, however, but him talking to the PI of the project and
taking credit for my discovery of the previous evening. I walked over and was astonished to hear him
saying to the PI, “I verified the compound this morning, so we’re on our way.” Apparently, he saw my
lab notes of the evening before, duplicated my test that morning, and now was taking credit for it as his
own!
When I got him in private, I was very upset and told him that the last, crucial step in the
experiment—the one I did the previous evening—was my idea and my work. He laughed in my face and
said that I was only tinkering around with some obvious strategies and that sooner or later one of us
would finalize it. In other words, he was entirely dismissing the importance of my work the night before
and arguing that the outcome was inevitable no matter which one of us did it. So, he was claiming the
work as largely his own because the project was his and he did most of the intellectual work.
How should a lab resolve this problem? In a situation like this, who should get credit and what
should the decisional process be?","We were surprised to discover that the literature on what Nicholas Rescher has called “credit allocation rules” in science is rather scant. This is in sharp contrast to the rather large literature on assigning authorship credit, and the scandalous literature on researchers appropriating ideas from one another and then claiming credit for them. Unfortunately, the investigator who is looking for some apriori blueprint or algorithm that spells out who should get credit for what discovery and how much credit will be hard pressed to find that template. But only a little reflection is needed to suggest why that omission exists. 
Consider some of the more obvious bases or justifications for allocating credit in scientific research: originality of the research project or experimental idea; ingenuity in developing the research design; persevering through the intellectual and physical rigors of gathering data and conducting analyses; developing critical, perhaps extremely novel experimental materials; providing critical, sometimes ingenious technical support; offering novel or even brilliant insights at any point along the research trajectory; assessing the value of a particular discovery within the overall research project, (e.g., did the discovery play a modest role, or was it momentous in realizing the project’s goal?); calculating the value of the discovery’s contribution to contemporary scientific knowledge (e.g., is that knowledge expanded, refuted, or better understood in light of the new discovery? Has the discovery enabled new and promising lines of research?); and, of course, deciding the value of the scientific discovery relative to its enhancing human flourishing. As such, it isn’t difficult to discern why no apriori schema is available for ascribing values to these factors because any research project is abundantly rich with contextual details like these that would inform and differentiate case-by-case deliberations about assigning credit.
Moreover, the fact that the form of most research is highly collaborative makes for additional problems. If every member of a research team contributed “equally,” then, following Aristotle, we would treat equals as equal and give everyone equal credit. Similarly, if the project design was such that each individual’s work was equally constitutive of and essential to the end result—or each individual’s contribution was so tightly and essentially integrated with all the others’ that it would be impossible to isolate one from the other—then we would probably not hesitate to say that the credit must be shared equally.
But much research activity is not nearly so equally distributed. Different tasks are delegated to different people or different groups, each one possibly requiring different levels of expertise or contributional weights—from performing sheer “grunt” work to performing tasks that might require extremely sophisticated knowledge and skill. Thus, while one might greatly value a remarkable insight on solving a complex problem, the experiment might nevertheless be impossible without someone else’s contributing a complex reagent or a ninth generation knockout mouse. Not only do all these “contributional interdependencies” exist but as highly interdigitated, they further complicate judgments about a discrete contribution’s value. 
We would be remiss, incidentally, if we failed to note that the problem of assigning credit for a scientific discovery is rampant throughout science’s history, prompting Stephen Stigler in 1980 to enunciate Stigler’s Law of Eponymy: “No scientific discovery is named after its original discoverer.” Confirmatory evidence for Stigler’s Law abounds. Alfred Russel Wallace had published papers on natural selection prior to Darwin’s 1859 masterpiece, On the Origin of Species, whose ideas might have more than influenced Darwin’s work. Gaussian distributions were not discovered by Gauss, nor was the Pythagorean Theorem discovered by Pythagoras. And to his credit, Stigler admits that Stigler’s Law was discovered by the sociologist Robert Merton.
The crux of the contributor’s dilemma involves differing interpretations about the originality and significance of the graduate student’s efforts. The post-doc understands the graduate student to be performing experiments that are obvious, straightforward and mundane. Although the post-doc would admit that the assistant’s experiments are critical to the ultimate research deliverable, i.e., the newly synthesized compound, the post-doc would probably argue that those experiments more require physical and mental stamina than scientific talent or skill. The graduate student, however, understands her experiment’s succeeding in synthesizing the compound as a virtual “breakthrough” rather than a predictable, mundane moment in the research project’s trajectory. And for that she wants recognition, i.e., credit. She sees her work as unique, skillful, and precious. The post-doc sees her contribution as menial, inevitable, and ordinary, especially in light of the project as a whole, whose creative and professional ownership he believes are his. How, then, does one resolve this problem?                                                     Let us assume that the PI is unable to adjudicate the dispute to the satisfaction of the graduate student and the post-doc. The next step might be to recruit a group of experienced scientists working in a related area of research, presenting them with the issues and disagreements of this dilemma, and requesting their opinion. A preferred, but perhaps less likely, alternative would be if the institution had installed a research ethics ombudsman or consultation group that could be involved in resolving the dispute. This approach is a distinctly Aristotelian one, looking to experienced and presumably virtuous individuals who will analyze the relevant issues and make a fair and just decision. At least two claims whose truth the group will focus on are the post-doc’s assertions that the graduate student’s experiments were “obvious” and that sooner or later, one of them would synthesize the compound without much difficulty. The committee’s considerations will likely focus on whether or not the nature of these synthesizing experiments were developed in advance, whose creative idea they were, how novel that idea was, and how complex it was to implement. Also, to the extent that the post-doc seems to want the entirety of the credit for himself, his collaboration with the graduate student must be analyzed. Was she, for instance, doing nothing but dutifully carrying out his ideas and orders, or was she contributing her own and how significant and original were they for the realizing the project’s objective? 
In his famous paper, “The Matthew Effect in Science,” Robert Merton—whom Stigler credits with coming up with “Stigler’s Law”—notes that the more famous or authoritative one is in the scientific community, the more likely he or she is to get a disproportionate amount of credit for a scientific discovery.6 Thus, Merton notes how Nobel laureates will not only sometimes refuse to place their names first on an authorship list, but might even remove their names entirely for fear that readers will simply give them all the credit and fail to notice any of the other authors. (The “Matthew Effect” derives from the passage in Matthew, 25:29: “For unto every one that hath shall be given, and he shall have abundance: but from him that hath not shall be taken away even that which he hath.”) 
We cannot dismiss the idea that the post-doc might be suffering from a Matthew Effect or, better, a “Matthew Syndrome.” He understands himself as the authority figure here and perhaps simply assumes that he is entitled to all the credit for the research discovery. If so, then such narcissistic assumptions might need to be checked by something like the institutional procedures we are proposing here. 
Of course, there are practical challenges with all our suggestions: How likely are universities to establish a consultative process as described above? Will their faculties endorse, support, and participate in it? How likely is it that most graduate students would even argue the matter beyond the post-doc and take it to the lab’s PI (much less to a formal consultation committee)? Yet, to the extent research universities would establish and publicize such measures for resolving disputes among investigators, they might provide something of a remedy for investigators suffering from the “Matthew Syndrome.” Failing all these recommendations for resolving this dilemma, perhaps the only words of wisdom left for graduate students such as the one above are: Choose the post-doc(s) with whom you work carefully. "
"Graduate students A and B are working on somewhat different but sometimes
overlapping aspects of the same project at the same university. Their labs are side-byside, and they share ideas often and compare data occasionally.
In one of their discussions and without realizing it, Student B suggests a novel
experimental idea to Student A. A is immediately struck by the idea’s value, but he does
not relate his insight back to B. Instead and in secret, Student A implements the idea
and begins a series of experiments and data collection. While this is happening and
some weeks later, Student B realizes the same idea. She quickly discusses it with
Student A, who, unbeknownst to B, is already well along in using it.
Student B is finishing up a group of experiments and cannot start anything new.
That allows Student A to finish his data collection and write up the results. Student A
presents a finished paper to his PI without any acknowledgement of Student B. Upon
reading the paper, Student B is enraged and claims that Student A committed plagiarism
by using a critical idea of hers without acknowledgment.
Please comment. ","Disputes over assigning credit in science are common. Often they take the form of
disagreements about “who was first” in making a finding of scientific importance. So, in
1876-77, Robert Koch and Louis Pasteur argued fiercely over who was the first to
discover the cause of anthrax. In 2003, Robert Gallo and Jean-Luc Montagnier publicly
announced they would stop arguing over who was first to discover the human
immunodeficiency virus and that they would share the credit equally. In 1962 at their
reception of the Nobel Prize, James Watson and Francis Crick committed the
unforgivable indiscretion of failing to adequately acknowledge Rosalind Franklin’s
contribution to the discovery of DNA.
The overriding cause for disputes over who was first to make an important
discovery is that most research doesn’t occur in a social vacuum, but rather in the midst
of a hard-working, global community whose member scientists are in intense
competition with one another for prestige and awards.
As such, they pay extraordinarily close attention to each other’s work by reading professional journals,
attending conferences, and exchanging ideas through professional forums. They study
and try out one another’s ideas, vary and revise them, and test new hypotheses—all the
while hoping to be first in announcing significant progress to the scientific community.
An intense concern about one’s own productivity coupled with a close scrutiny
of what one’s competitors are doing can compound the credit allocation problem
because it occasionally results in similar discoveries occurring virtually simultaneously—
not unlike what happened in the above dilemma. To take a few historical examples (and
there are many), Newton and Leibniz discovered the calculus at virtually the same time;
Darwin and Alfred Russel Wallace both discovered evolution; sunspots were discovered 
by four independent scientists (among them Galileo), all in 1611; and Carl Wilhelm
Schelle discovered oxygen in 1773 while Joseph Priestly discovered it a year later.
Just so, Students A and B are embroiled in a debate over credit—about who was
first to hit upon the valued idea—because they work in intensely social environments;
they have the opportunity to share, use, and test one another’s ideas, methods, and
data; and they are explicitly aware that their institution expects them to excel. How,
then, ought their dispute over receiving credit be resolved?
We might begin by attempting to determine as precisely as possible what B
initially said to A. Because A is claiming that the idea is actually his, we would need to
assess the degree to which A elaborated and translated whatever B said to him into the
experiments he eventually conducted. Unfortunately, this may be extremely difficult to
determine because of the likelihood that A and B will misremember their initial
discussion. If the function of memory is essentially reconstructive as psychologists like
to say, the chances are good that each will reconstruct the story he or she tells to suit
his or her personal ends.4
Nevertheless, if we go by the dilemma itself, the idea whose originality is in
dispute was not fully appreciated or well-formed in B’s mind during her initial
conversation with A. What presumably happened is that B speculated, mused, or
elliptically talked “around” something that then inspired a novel insight in A’s
consciousness. (So, it is easy to imagine that at that point of original discussion, Student
A understood the novel idea to be his by way of his extrapolation of B’s musings.) The
moral challenge, then, involves determining the degree of A’s originality or creativity in
translating B’s intimations into a scientific deliverable. If it turns out that A’s work
entirely derived from or simply copied the content of B’s original conversation, we
would be inclined to find him guilty of plagiarism (i.e., intellectual theft). But if his work
showed striking originality and creativity, and he only used B’s conversation as a point of
departure or inspiration leading to something strikingly original and important, we
would be inclined to credit A.
Perhaps it would be useful, then, to construct an “originality continuum.” At one
end or pole, we could place a morally unproblematic example of scientific originality,
such as one that Alexander Graham Bell reportedly made in regard to what he called the
“harmonious telegraph.”* As told by Malcolm Gladwell in a 2008 issue of the New
Yorker, Bell was consumed by the problem of the telephone and was in fierce
competition with other inventors.
 In 1874 he was spending the summer with his
parents in Brantford, Ontario and one day, he went for a walk along the banks of the
Grand River to muse over the problem. As he watched the currents of the river,
Gladwell reports that Bell “knew the answer to the puzzle of the harmonic telegraph.
Electric currents could convey sound along a wire if they undulated in accordance with
the sound waves.” Let us suppose, then, that the Grand River metaphorically
“suggested” the solution of the harmonic telegraph puzzle to Bell. But if the Grand River
had human qualities such that it could speak and learn of Bell’s appropriation of its
“suggested” idea of undulations, could it legitimately accuse Bell of stealing its “idea”?
Surely not. The “idea” that the Grand River suggested to Bell was extremely
circumscribed and infinitely removed from the way Bell used it in his invention. We 
credit Bell with the invention of the telephone because of the remarkable creativity with
which he recognized and translated the idea of the Grand River’s undulations into
telephonic technology. Analogously, then, if Student B suggested the disputed idea to
Student A in the way the Grand River suggested the solution of the harmonic telegraph
to Bell, we would dismiss B’s allegations of intellectual theft out of hand.
At the other pole of the originality continuum, however, we could posit a frank
instance of plagiarism. For example, the March 12, 2007 issue of Chemical and
Engineering News reported that Stockholm University in Sweden had sanctioned an
associate professor of chemistry, Armando Cordova, for misconduct.4
Cordova was
accused of taking research ideas he had heard at professional conferences and seminars
back to his lab, conducting (often poorly designed) experiments around them, and then
quickly gathering and publishing data without giving due credit. The gist of all the
accusations boiled down to a single complaint: Cordova committed plagiarism by failing
to acknowledge others in his publications as the originators of the critical ideas that
informed and directed his work.
The elements of Cordova’s case smack of Student B’s complaint against A. B
claims that like the presenters from whom Cordova stole ideas, she presented an idea to
A, which he then evolved into an experiment, proceeded to collect data, and then took
assumed the credit without acknowledging B’s critical contribution. Like Cordova’s
accusers, B is enraged, claims that A stole her idea, and accuses him of plagiarism.
With the Bell and Cordova cases serving as the two poles of our originality
continuum, we would then attempt to locate the originality of A’s appropriation of B’s
original discourse somewhere along it. If the findings turn out to be nearer to the Bell
end of originality or creativity, we would be inclined to exonerate A and dismiss B’s
complaint; if nearer to the Cordova end of outright intellectual pilfering, we’d be
inclined to give B the credit and penalize A. If the findings are somewhere in between,
we might resolve the dilemma by giving equal credit to both.
Note, too, that we would have to deal with B’s claim of eventually hitting upon
the idea herself. But according to the dilemma, this presumably occurred some time
after B’s original conversation with A, who claims to have had the idea from the start. In
order to substantiate A’s claim that he was first with the idea, we would have to check
his lab notebook, observe the dates of his experiments, and determine if they actually
antedated B’s hitting upon the idea. Again, questionable or unreliable memories along
with insufficient documentation might complicate this.
At any rate, an approach using these strategies might go some way to resolving
the credit assignation problem of our dilemma. It does not, however, address another
troubling aspect of this case. Students A and B are working at the same institution on
overlapping research projects. While the competition in science as to “who gets there
first” is admittedly intense, it is very disquieting when investigators from virtually the
same laboratory cannot trust one another in allocating credit fairly. And it is not only
disquieting from a principled perspective—i.e., one should receive credit proportional to
the temporal priority of her discovery and the merit of her contribution—it is
disquieting from a purely pragmatic perspective: Investigators from the same
institution who fear that a co-worker will take credit for their ideas will, by that very 
fact, be inclined to conceal their ideas from one another. That concealment might then
retard the productivity of their labs and the accumulation of knowledge that would
ordinarily result from a collective, institutional effort.
One wonders why A was so reluctant to share his insight with B. Did he fear or
profoundly dislike her? Was he convinced that if he disclosed the insight to B, its credit
would be lost to him forever? Did he lack certain skills in moral analysis such that he
was unable to articulate why the idea, as well-formed, belonged to him? Did he lack
negotiation skills that would enable him to describe the insight to B and then propose
that they work on the idea together, with him as the primary investigator? One is
reminded of so many authorship disputes that attest to communication failures among
the investigators to decide such issues before a paper is begun. Once the paper is
written, however, investigators emerge from the lab’s woodwork, claiming authorship
credits for the flimsiest of reasons.
Labs confronted with these kinds of issues, and we suspect they occur relatively
often, should consider communication skill building among their personnel, especially
involving negotiation and conflict resolution strategies. While it can be somewhat
unpleasant, anticipating how conflicts and disagreements can arise and deploying
preventive strategies before quarrels get started is obviously the best approach. Good
lab directors, then, should be acutely sensitive to the problem of allocating credit for
discovery as discussed here. When investigators fail to appreciate the intensely social
ways that scientific discovery proceeds and the moral problems that can result, nasty
problems over assigning credit should be expected.
All of this bears on the moral formation of Students A and B. If the lab director
simply dismisses Student B’s accusations and complaints without any response, what
effect will this have? Stockholm University was itself criticized for letting Armando
Cordova off lightly. His sanction consisted of his attending an ethics course and having
to present all his papers intended for public consumption to his dean for review before
he submitted them to journals. Yet, the report on Cordova’s misconduct indicates that
he continues to take credit for work that is not his.5
 His professional trajectory is
obviously threatened by these events and to the extent that he is a talented and hardworking scientist, his misbehaviors can end an otherwise promising career.
Typical penalties for plagiarism include disgrace, humiliation, ostracism and
other “shaming penalties.”
 Because it is obviously preferable to never have to call
upon these interventions, laboratory leadership has the responsibility to be keenly
vigilant about and responsive to alleged improprieties about misconduct; to include
ethics seminars and case discussions in the curriculum; to initiate skill building exercises
focusing on communication and negotiation as mentioned above; and, when they occur,
to adjudicate disputes with Solomonic wisdom. These are considerable expectations.
But universities cannot disavow their responsibility to graduate scientists who are not
only technically competent but who are adept at exercising moral sensitivity and insight. 
*We are aware, incidentally, that some historians might fault our using the Bell example
as one of morally unblemished originality. They might point out that Bell sometimes
visited the Patent Office in Washington, DC, whereupon after one such visit, he made a
sketch in his notebook of a transmitter that was identical to the one his arch rival, Elisha
Gray, had just filed in the Office. Did Bell, as Seth Shulman contends in his revisionist
account of the invention of the telephone, The Telephone Gambit, steal a critical idea in
the telephone’s invention from Gray? Was he as morally above reproach as we are
making him to be? Perhaps not. In the essay above, though, we are only assuming that
his ideas on sound wave undulations, as suggested by the Grand River example, were
clearly his and not a competitor’s.

"
"David is a new postdoc in Dr. Goliath’s lab. Upon David’s arrival to the lab, Dr. Goliath assigned
him a few experiments to firm up some results of a paper that had been rejected by a journal.
These experiments had not been performed because the technician who was working on the
project and was the rejected paper’s first author had since left the lab. David was given a copy
of the (rejected) manuscript to review and to assess what needed to be done for a second
submission. After reading the paper, David felt that the quality of the writing was poor and
that, along with including the results from the control experiments Dr. Goliath asked him to do,
the manuscript needed to be completely re-written.
David expressed all this to Dr. Goliath, who agreed that David should take ownership of
the paper and improve it. Upon completing and adding the results of the control experiments
and then re-writing the original manuscript entirely, David re-submitted the paper without
consulting the original author who had performed the bulk of the work of the original
manuscript. The reviewers gave enthusiastic reviews of the re-submission and the paper was
accepted with minor revisions
Was it appropriate that David replaced the original author as first author? Was David in
the wrong to have totally re-written the manuscript without the permission of the technician
who had written the original (rejected) paper prior to leaving the lab? Should the technician
have been informed about the changes to the manuscript prior to the new submission? Should
the technician have been invited to comment on or contribute to the new submission?","A key source of ethical guidance in resolving this dilemma is the opinion of the International
Committee of Medical Journal Editors (ICMJE), which recommends that:
Authorship credit should be based on 1) substantial contributions to conception and
design, or acquisition of data, or analysis and interpretation of data; 2) drafting the
article or revising it critically for important intellectual content; and 3) final approval of
the version to be published. Authors should meet conditions 1, 2, and 3 … Each author
should have participated sufficiently in the work to take public responsibility for
appropriate portions of the content. Suppose that the original, lab technician author found out about the successful re-submission
of the paper and complains that he is no longer first author. (Indeed, we are not told whether
he was retained as an author at all, but let us assume he was.) Using the ICMJE’s authorship
criteria, how might an ad hoc committee (or reasonable facsimile) resolve such a complaint?
Certainly, a key issue in deliberating over who should be first author must revolve
around the re-submission’s “intellectual content.” We are told that David performed new
control experiments, whose findings he included in the re-submission, and that David also
completely re-wrote the original paper. But if this is the extent of David’s work, then the lab
technician seems to be able to make a strong claim to be retained as first author—that is, if his
original “contribution,” i.e., the experimental design, and most of the data and their analyses
and interpretation, were substantially if not “phraseologically” retained in the re-submission
and constituted the bulk of the re-submission’s findings.
To appreciate this, consider the following hypothetical situation: Instead of assigning
the do-over of the paper to David, suppose Dr. Goliath has a graduate student perform the new
control experiments. Upon collecting that data, Goliath then hires a ghost writer/copy editor
(who is not a professional scientist) and says, “Here’s a rejected manuscript with some new
data. I want you to re-write this paper as best you can and incorporate the data from these
new experiments.” Now, it is quite possible that this copy editor could produce a paper very
similar if not identical to David’s, but we would probably hesitate giving him an authorship
credit at all, much less assigning him first authorship.
Consequently, a crucial question that an ethical review of this case would have to
address is: How different and elaborate must the intellectual content of David’s resubmission
be from the original in order for David to replace the lab technician as first author? Did the
overall conception and design of the original paper’s experimental approach change
significantly with the re-submission? Were the data analyzed and interpreted differently?
Were new implications of the data presented?
The outcome of this analysis would answer the above question about the propriety of
David’s replacing the original author as a new first author. As to the question, “Was David in
the wrong to have totally re-written the manuscript without the permission of the technician
who had written the original (rejected) paper prior to leaving the lab?” we say, “Probably not.”
Considered as intellectual property, the original, rejected paper and its ideas belong and have
always belonged to the lab, so that David doesn’t need the technician’s permission to revisit the
original paper.
This is a very important point if the University would ever wish to patent any
aspects of the materials of the original paper (regardless of whether it does or doesn’t appear
in a professional journal). The University owns and has always owned the paper’s ideas and
discoveries such that had the original paper been submitted and been accepted but the lab
technician had left the lab for a new position in the meantime, he or she would have to reveal
the fact that the research was conducted at the University while he was employed there, and
not give the erroneous impression that his new employer—whose name would certainly appear
on the paper as his current employer—owns the paper’s content as intellectual property. In
sum, the University, through Dr. Goliath, seems certainly within its rights to re-assign the
rejected paper to someone else and to have that individual revise the paper accordingly.
However, we strongly believe that the technician should have been invited to respond
to the revision before it was re-submitted—both to respond to its content as well as to his
losing first-authorship. Indeed, it seems remarkably unprofessional as well as a violation of the
ICMJE’s guidelines to place the tech’s name on the re-submission—if that in fact happened—
without his having reviewed and approved it. A pre-submission communication from David to
the technician should have informed him of the revision, explained why he (David) deserves
first authorship, and invite the technician to contribute to the revision. As occurs so often in
these kinds of cases, treating an original research contributor as though he or she no longer
exists explains how so many of these disputes originate.
So, let us conclude by returning to the issue of assessing the scope and content of
David’s revision. If we imagine an authorial continuum whose one pole is a vastly re-written
but nevertheless relatively intact preservation of the lab technician’s original intellectual
contribution(s) with the other pole of the continuum a completely new version of the original
paper’s experimental design, data, and findings, then first authorship should be determined
according to which pole on that authorial continuum (represented by David at one end and the
lab technician at the other) the resubmission’s content veers and lands. As this dilemma might
play out, however, it would be easy to imagine the lab technician’s ire should he read the resubmission’s eventual publication and exclaim, “But these are mostly my ideas and data! And I
was never contacted!” Again, some thoughtful communications among David, Dr. Goliath, and
the lab technician prior to the revision’s being re-submitted is the preferable approach to take.
"
"A PI moves his lab to a different university, but a few of his postdocs and students stay back.
Once settled in, the PI decides to rewrite manuscripts already in preparation, changing the
authorship order to favor those who joined him. He also reserves the right to prohibit
publication of any research conducted in his old lab, on the presumptive authority of his role as
PI.
Is this ethical? Please comment.","At first blush, this PI certainly seems to be a vindictive fellow, trying to “punish” his former
graduate students and postdocs for not accompanying him to his new lab by rewriting their
manuscripts so as to diminish or delete their authorship status or claims. If the ethical propriety
of his rewriting was challenged, would he be able to defend himself in any kind of morally
convincing way?
Our response would inquire whether the PI’s rewriting of the manuscripts resulted in an
occasional change of wording or phraseology or whether it resulted in a considerable overhaul
of the papers’ intellectual content. If the papers’ experimental designs, methods, data
gathering, analyses, findings, and implications remained essentially the same after the PI’s
rewrites—such that the original content of the papers remained unchanged—then his behavior
seems disreputable. To the extent that the disfavored investigators’ contributions were
intellectually and substantively retained (and only reworded), their position on the authorship
list should remain unchanged. On the other hand, suppose the PI was unhappy with the work
of the students-who-stayed-behind, deciding that their contributions reflected “poor science.”
His rewrites might be justified if he then proceeds to delete their work or replace it with new
material that they didn’t contribute. To really pass ethical muster, however, he should be able
to make his case for rewriting to some committee or the Office of Research Compliance.
Questions over the second issue of this dilemma, namely about the PI’s claiming a right
to prohibit publication of any research conducted in his lab, might also go to the University’s
Office of Research Compliance. We believe that in instances where the PI and members of his
research team part ways, the individuals who performed the research should retain a moral
right to publish without the PI’s permission, as long as the authorship credits accurately reflect
the investigators’ contributions, are presented in good faith, and comply with the standard
rules on authorship.
As noted in any number of these website cases on authorship, university-based
investigators ordinarily do not own their research—their University does, assuming the grant
award came to it, which is usually the case.
 The research team serves as the University’s subcontractors/employees who promise to execute the research program described in the grant application. Thus, when a PI “takes” a grant with him or her to another institution, it is only with the permission of the University to which the grant was originally awarded. Indeed, the University reserves the right to retain the grant and appoint a new PI. Universities will sometimes not exercise that option upon a PI’s departure, however, because the University might be unable to persuade the grantor that it (the University) could adequately replace the PI and the departing research team so as to keep its contractual promise to do the research. Also, just as universities might “lose” grants when a PI takes a grant and his research team to another institution, so universities “get” grants when new hires bring research awards with them. From a purely ethical perspective, however, a PI’s belief that he has the right to prohibit publications from his laboratory solely because he is the PI is not convincing. From an ethical perspective, the PI must have substantive reasons, usually targeting the quality of the paper’s science, to justify withholding it. As long as a publication is submitted in good faith and complies with the usual expectations of authorship, PIs should welcome rather than prohibit the submission of such publications from their labs. After all, their professional responsibilities include not only discovering and disseminating scientific knowledge but advancing the careers of their laboratory personnel.
Our impression is that PIs often succeed in blocking such publications on pragmatic
rather than moral grounds. For example, an investigator who believes she has written an
excellent paper but wishes to remain employed in a lab will probably not stand up to the PI who
opposes her submitting it. Although she could submit the paper regardless, her PI would likely
become upset upon her doing so and might initiate some punitive action against her.
In the above scenario, however, the PI cannot directly harm his research team members
who stayed behind. Should they wish to submit manuscripts on their own, however, they
would have to consider whether the PI merits an authorship credit per his contribution. If the
PI did make such a contribution but forbids the submission, the authors might just delete the
PI’s contribution from the manuscript—which might prove impossible if the PI conceived and
directed the bulk of the research program. If the investigators could ethically effect such a
deletion and still wish to proceed with the submission, they could exclude the PI as an author
and instead acknowledge him or her at the end of the manuscript —in which case professional
courtesy would require contacting the PI and informing him of the intended submission. At
that point, it is hardly inconceivable that the PI might submit a blistering note to the journal
condemning the manuscript, which could easily doom its chance of publication.
Finally, if the research team would decide to submit the manuscript without any
mention of the PI, they would be well advised to confer with their superiors and perhaps the
University’s Office of Research Compliance. That office might decide, for example, that if the PI
can take his grant with him to another institution, then that implies that he can exert a strong
ownership claim over the data and hence control its dissemination. Thus, even if his intentions
to control publications are maleficently motivated, a PI might be able to block publication of
any papers coming out of his lab because his “ownership” of the data endures.
It is easy to see, then, how these pragmatic considerations and possibilities might
dissuade investigators from submitting papers in opposition to their PIs’ wishes. Yet, if such a
manuscript is actually a solid piece of work, then the losers from its nonpublication are not only
the research team members who wrote it, but the scientific community that is denied the
research findings and, by extension, whoever might someday practically benefit from them.
The easiest way to have averted this entire mess, of course, would have been to have
negotiated all these authorship issues between the PI and his investigators prior to the PI’s
departure. As the case actually unfolded, though, it seems we have a PI whose understanding
of fairness is overwhelmed by feelings of vindictiveness and narcissistic wounding. In response, 
he reverts to morally objectionable strategies to maintain his sense of power. This is the darker
side of scientific work that academic institutions should take into account when they educate
their scientists on responsible conduct in research. While PIs obviously exercise authority, its
fundamental purpose should be focused on doing good research and good science. There is no
reason why the exercise of authority cannot be tempered by a keen sense of humility.
Tyrannical PIs like the one above might indeed be productive, but they hardly qualify as ethical
role models.


"
"George Washington is one of two postdocs working in Dr. Big’s lab. The other postdoc, Dee
Nye, is older and has more years of experience than George, but although she is approaching
the end of her postdoc term, she has no first-author publications nor has she received any
extramural grants. Because Dee will need to leave the lab soon and find a position elsewhere,
there is a keen desire on her and on Dr. Big’s parts to make her marketable. Compounding her
overall lack of productivity is the fact that Dee does not get along very well with her coworkers; her presentations are poorly delivered; and her experimental designs are frequently
flawed.
Dr. Big likes George and tells him that he (i.e., Dr. Big) has taken it upon himself to write
a manuscript with Dee as primary author and that he will create all the necessary figures, albeit
using Dee’s data. He also tells George that he has written a rather complimentary letter for
Dee and embellished her qualifications in order to improve her job prospects.
George thinks that it is exceedingly unfair that Dee can be so unproductive and
unprofessional in the lab, yet emerge from this with someone else writing her manuscripts and
providing a glowing letter of recommendation. When he confesses this to Dr. Big, Dr. Big
answers, “I know, I know. But someday you’ll have to manage a situation like this, and you’ll
just want to be rid of this person. Besides, if I want to make her the first author on a paper, I
have that authority, don’t I?”
George is not convinced by Dr. Big’s argument, but he isn’t going to quarrel with Dr. Big
and he certainly won’t miss Dee Nye. Nevertheless, Dr. Big’s behaviors seem ethically
problematic. Please comment.","Dr. Big might be a fine scientist, but he’s not a good mentor. First, he plans to write a
recommendation letter that will frankly misrepresent Dee’s abilities and interpersonal
behaviors. The practical consequence is that her inadequacies might well follow her to her next
job and continue to cause problems. Dr. Big might argue that he’s working on Dee’s behalf,
thinking perhaps that she just needs more time to develop a more mature set of professional
behaviors. One could alternatively argue, though, that Dr. Big is primarily motivated to be rid of
Dee, and that his true motivation is self-serving (which rarely, if ever, serves as an ethical
justification). Rather than undertaking the effort to improve Dee’s professional conduct and
skills, he takes the less effortful path of misrepresenting her conduct and accomplishments.
(And we are assuming that Dee performed inadequately as described. But is her less than
stellar performance in some way attributable to Dr. Big’s very limited capacity to be a good
supervisor? Did Dr. Big allow and support Dee’s exploring her scientific interests or did he have
her doing relatively unproductive work in the lab, perhaps for his own gain?)
Second, Dr. Big is going to write a paper for Dee and position her as first author. This
will count as a second misrepresentation of Dee’s ability, assuming Dr. Big makes the primary 
intellectual contribution. Of course, it co-opts Dee into committing the same,
misrepresentational offense. Dr. Big is exaggerating Dee’s contributions to the paper, and his
argument that he has the authority to do so certainly doesn’t pass ethical muster. If authority
admits moral connotations—such that the appropriate exercise of authority consists in
modeling moral behavior and insisting that one’s charges do the same—then Dr. Big is
confusing moral authority with power. One is reminded of Socrates’ famous question in the
dialogue Euthyphro: “Is something good because the Gods approve it, or do the Gods approve
of something because it is good?” If Dr. Big is one of the “Gods,” he needs to exercise his
authority in accordance with ethical concerns about the integrity of his lab, his institution, and
all the relationships that are at stake (including the one with Dee’s future employer). Just
because he has “godlike” power doesn’t mean his exercise of it is automatically good.
Third, Dr. Big shares all of this with George, the other postdoc in the lab. Surely, this
counts as an unprofessional conversation. One might see it as a “boundary violation” in that it
muddies the relationship between Dr. Big and George—i.e., George has now become Dr. Big’s
confidant rather than just a mentee. Also, his confiding in George suggests that Dr. Big might
have some uncomfortable awareness of the wrongfulness of his conduct, so he chooses to
confide in someone who, predictably, will not call him on it. By revealing this all to George, Dr.
Big perhaps relieves his conscience, but he takes the less-than-responsible course by passing
this information along to a predictably benign, passive, and nonthreatening individual.
Worse, however, is that just as Dr. Big has co-opted Dee into misrepresenting her
authorship, his confiding all this to George makes George complicit in the misbehavior: If Dr.
Big and Dee’s misrepresentations are ever discovered, and George’s foreknowledge of their
intentions and actions becomes known, he might be harshly penalized for failing to call the
organization’s attention to this turpitude.
For all these reasons, it is difficult not to come down hard on Dr. Big. Quite possibly,
had he intervened in ways that a committed and skilled mentor would when the first signs of
Dee’s professional and relational deficits became apparent, this unpleasant scenario could
have been avoided. Did Dr. Big suffer from excessive optimism, thinking that somehow, as the
years passed in his lab, Dee’s behaviors would magically improve without the need for any
explicit intervention? Indeed, was Dr. Big ever trained in mentoring so as to know what to do
when mentees like Dee first begin presenting problems?
This invites the suspicion that Dr. Big may well be part of an institution that is aiding and
abetting his failures. The institution may be failing to: 1) provide training to its scientists in
mentoring skills in the same way that institutions typically provide ongoing training on grantgetting skills; 2) monitor mentoring conduct, by soliciting reports from mentors about their
mentoring activities and soliciting feedback from mentees about the same; and 3) reward
appropriate mentoring conduct as it rewards success in winning grants, invitations to present
high-profile lectures, membership invitations to prestigious professional associations.
Dr. Big‘s poor mentoring speaks to the need for training programs to be designed and
made available for all persons stepping into a mentoring role, lest one make the huge
inferential error that because someone is a competent and productive scientist, he or she ipso
facto has the pedagogical and management skills to be a decent mentor.
Ultimately, mentorship skills are considerable and complex, and should not be shrugged
off. Mentees deserve very capable supervisors, especially as they progress towards being 
responsible, independent scientists who might, someday, be faced with mentoring challenges
of their own."
"Some years ago, I worked as a bronchoscopy technician on a lung transplant service.
This service maintained a very aggressive post transplant surveillance regimen that was
formally connected with the hospital's translational research efforts.
After lung transplantation, patients were seen 9 or 10 times over the course of
the first year. They routinely had bronchoscopy, which included a saline flush whereby
tissue from the lobe could be collected and then analyzed for signs of infection or
rejection. Additionally, patients underwent transbronchial biopsies with the tissue sent
to pathology for evaluation of developing allograft rejection. The tissue was also sent to
the research labs for collaborative translational studies. Patients also went through a
series of breathing tests, thoracic CT scans, and blood draws during their regular check
ups.
This aggressive follow-up was not without controversy. Many, probably most, in
the field believed it was necessary to detect rejection or infection early so as to
intervene rapidly and as effectively as possible. Others felt that these patients should
be left alone after transplant unless symptoms actually arose. I recall one transplant
group in particular claiming that their center's overall post transplant survival times are
just as good as those at centers that use the more aggressive regimen.
I believed that it was an honest question as to whether the aggressive
management at my facility was, in fact, providing better patient care. The central
problem was that lung graft survival times are less than desired overall and have not
changed much over the past decade. More research is needed to better understand
and be able to predict and treat episodes of lung allograft rejection before total graft
failure occurs and the patient dies. So, it is certainly fair to say that while aggressive
management for both clinical and research purposes might have problematically put the
patient at an increased risk without immediate personal benefit, transplant knowledge
gained through the diligent and extensive collection of clinical and biological data is the
only way to better understand the pathology of lung allograft rejection and why some
treatments do or don't work. Of course, the most likely beneficiaries of this knowledge
will be future patients, not the ones we are currently treating.                                                                                                      The second ethical problem with this research was the collection of lung alveolar
tissue by transbronchial biopsy for both clinical and research purposes. This is a
procedure that poses serious risks with even the possibility of death. However, the
procedure is currently the gold standard for diagnosis of lung allograft rejection. The
problem is that while we wanted to take biopsies for both clinical as well as research
purposes, sometimes the decision had to be made to skip one or the other because of
an occasionally limited ability to obtain tissue.
Multiple biopsies are the gold standard because rejection can be occurring in a
portion of the lung not sampled, thus leading to false negatives. But when the tissue
samples at a particular visit only go to research and the patient eventually goes into
rejection, I have wondered whether we would have caught some of the false negatives
sooner had the samples only gone to the clinical lab.                                                                                                            Perhaps there is no ethical solution to these issues because lung transplantation
is hardly a perfect science. But there certainly seems to be ample room for ethical
reflection on the somewhat conflicting stakes between research and patient care, and
the clinical uncertainties that are part and parcel of lung transplantation. ","One of the problems posed by this dilemma is whether or not it was ethically acceptable
to subject transplant patients to a highly aggressive post-transplant regimen of
procedures to check for allograft rejection. One might argue, as the dilemma
contributor does, that this regimen, which included tests of a purely research as well as
clinical nature, might have disposed patients to excessive or unreasonable risk (not to
mention the unpleasantries involved). Of those tests that serve a purely clinical value,
however, we are of the understanding that “surveillance” bronchoscopies with multiple
(i.e., at least 6) transbronchial biopsies for early detection of clinically occult acute
rejection are the gold standard worldwide, as the number and intensity of acute
rejection episodes are the strongest predictors of subsequent graft dysfunction and
patient death. While there may be some investigators who claim equal results without
this amount of follow-up, those claims do not seem to represent mainstream transplant
understanding and practice. Moreover, our experience with transplant recipients has
shown that they very much desire aggressive follow-up. Consequently, we find the
author’s argument, i.e., that aggressive clinical follow-up is probably what the standard
of care should require, compelling. But what about those tests that are purely of a
research nature—the ones where, according to the dilemma contributor, “the likely
beneficiaries of this knowledge will be future patients, not the ones we are currently
treating”?
If the risk burden of these tests, as measured by the quantity and gravity of
adverse events or complaints, is not deemed excessive or unreasonable by the
institution’s IRB or office of clinical trials, participants simply must be appraised of their
dual role as 1) patients about to undergo transplant and 2) research participants whose
post-transplant experiences will be closely monitored for scientific purposes. They
must be informed that certain of the tests they experience will not help them personally
but will rather help researchers develop better transplant interventions for future
patients.
Acknowledging research participation by way of these informed consent
considerations suggests that patients be allowed to opt out of them, or that they can
rescind their consent at any time. At Emory University, for instance, the physician
performing a bronchoscopy for research purposes confirms that the patient has a signed
research consent form on file and asks at each visit if the individual still wishes to
participate.
The dilemma contributor’s transplant center is having patients fulfill both
research as well as clinical roles, which those patients have a perfect right to know
about. Indeed, one cannot imagine that the informed consent documents these
patients sign would omit that information. Furthermore, one would hope that the
various professionals who are seeing these patients are clearly distinguished from one 
another as clinicians and investigators. To the extent, however, that many of them,
especially physicians, play both roles, conflicts of loyalty can easily occur that could
compromise informed consent discussions with patients. It is possible, in other words,
that clinician-investigators might pose informed consent conversations in such a way
that patients feel they have no choice but to acquiesce to the research studies, or they
might not be made sufficiently aware that certain of the tests have no clinical benefit for
them. The former is coercive while the latter is deceptive. Both, of course, are
unethical.
But the dilemma contributor raises a second problem per his suspicion that
biopsied material was occasionally sent only to the research arm of the study and not to
the clinic, which might have harmed certain patients who went into rejection. While we
will never be able to tell with sufficient confidence whether this investigator’s worries
are legitimate, it is hard to think that the research protocol in this case as vetted by the
institution’s IRB would not have stipulated the frequency and amount of tissue that
would need to be taken to satisfy both patient protection requirements as well as
research objectives. If the actual implementation of the protocol sometimes did not
accommodate or satisfy those stipulations, then it is easy to indict a lack of reporting or
oversight on protocol adherence as the culprit. Note, also, how this recalls the conflict
of loyalty mentioned above: that if a health professional was assigned to care both for
the patient’s clinical needs as well as collect tissue for research, he or she risks
becoming compromised by conflicting demands. (And it would not be terribly difficult
to imagine him or her rationalizing a decision that favors research interests, especially if
the investigators feel very pressured to collect adequate material.)
Still, an IRB would never allow the participants’ personal welfare to be
subordinated to their value as research subjects. So, if a conflict ever had to be
adjudicated about prioritizing where the patient’s tissue would go if it could go to only
one place, i.e., to a research lab or a diagnostic lab, morality would dictate the latter
over the former.
If the technician observed the clinical care of patients being compromised by the
investigators’ research interests, he should have reported it. This brings up the question
as to whether he didn’t think it his job, or that he feared reprisals for doing so, or that
he believed that reporting wouldn’t make a difference. Ideally, everyone on the
research team should feel comfortable bringing up concerns like this, but we know in
practice that such “speaking up” can be excruciatingly difficult to do, especially if, as was
the case here, the would-be whistleblower is someone without much power. On the
other hand, the dilemma contributor might have simply understood his concerns to be
nothing more than uncomfortable suspicions that ultimately lacked evidence. This
leaves us with the interesting and provocative question as to: At what point does a
population like this become “sufficiently” endangered by having their lung tissue go
clinically unexamined because, say, it is diverted to research? Until that question is
confidently answered, moral reflection over the quality of patient protections, the
possibly reckless endangerment of patients, and the design of and adherence to
biobanking protocols will remain inconclusive.


"
"Jane is a very motivated and bright graduate student who is trying hard to purify a protein in a
highly specialized area of research. Despite her perseverance, she meets with failure after
failure. Finally, she goes to her PI, Dr. Smith, who is an internationally recognized investigator in
Jane’s area of research, and confesses her problem. The PI is silent for a while and then says,
“Don’t fret. I’ll have something for you to look at tomorrow.” The following day when Jane
arrives at the lab, she sees an unpublished manuscript on her desk with a post-it note from Dr.
Smith that says: “Jane, read the methods and results sections of this paper. I think they might
contain the solution to your problems. But don’t tell anybody I gave you this. As soon as you
are finished, return the paper to me. And don’t make any copies of it.” The paper describes an
experiment that seems exactly suited to solving Jane’s problem. Sure enough and within a few
days, Jane has purified the protein using the approach. She gleefully reports all this to her PI
and returns the paper. She can’t help asking though, “Dr. Smith, I have searched the literature
high and low to find a method to help me with my project and found absolutely nothing. Where
did you get that manuscript?” to which Dr. Smith obliquely replies, “Oh, I’ve got a ton of them.”
Discuss the ethical dimensions of this scenario.","We purposefully omitted describing the origins of the paper Jane read because therein lies the moral
content of this dilemma. The paper could have been written by Dr. Smith or a student in his lab and
never published. Or it could have been a paper that Dr. Smith was reviewing for a peer-reviewed
publication or for the NIH as a research grant application. Or it could have been a paper that had been
reviewed for publication, was accepted, and was awaiting publication in the very near future. With an
understanding of the federal Office of Research Integrity’s characterization of plagiarism as “the theft or
misappropriation of intellectual property and the substantial unattributed textual copying of another’s
work,” 2
 let’s consider each of these possibilities.
Scenario #1: The paper was written by a former student of Dr. Smith’s who was working in Dr. Smith’s
lab at the time. The paper was never published nor was it ever submitted for publication.
Under these circumstances, there shouldn’t be a problem with Jane’s having access to and
working from the paper’s methods and results section. The reason is that Dr. Smith’s university, which
we shall call Exemplary U, probably owns the student’s work as intellectual property.3
 The only way the
student could lay an unproblematic claim to owning the work is if he had already received the
University’s permission for him to copyright the material. If the student never sought copyright
authorization or sought to publish the paper, Dr. Smith—as the university’s representative and under
whose direction and auspices the work was performed—would seemingly have sufficient authority to
allow other investigators in his lab access to it.
As just implied, an interesting twist in this scenario would occur if the paper’s original author,
who let us suppose is now working at another university, would want to publish the paper’s methods or
propose their use in his own NIH application. This situation happens occasionally, as investigators will
work together in a lab on a given project and subsequently go their separate ways. They might think
that they can take their data and methods from their previous workplace without worry because, after 
all, they created them. But their belief about their owning that intellectual property would be quite
problematic without an antecedent contractual agreement with the university at which their work
originally occurred.3
As the original methodology, which we shall call “the work,” was created at Exemplary U, the
university owns it and might wish to exert its property interest in that work.3
 The student investigator
will doubtlessly have signed an employment agreement with Exemplary U acknowledging the latter’s
ownership of his labor. So, if the student, who is now working at another university, would publish that
paper as his own or if his current university would want to patent those methods (i.e., the ones that
Jane used), Exemplary U would have grounds to sue (at least for breach of contract and perhaps
copyright or patent infringement).
Consequently, this scenario doesn’t appear to represent any moral turpitude on Dr. Smith’s
part. Nevertheless, when it comes time for Jane to write up her experiment for publication, she most
certainly should acknowledge her predecessor’s work in supplying the methodology she used. Indeed, if
she decides she wants to cut and paste the wording that describes the methodology from the original
paper, she is ethically obligated to contact the original author and invite him as an author on the paper.
There is a sense in which the wording of the methodology section belongs to him, and Jane would be
plagiarizing if she simply usurped that language and claimed it as her own. (This would not be
essentially different from a situation where Jack and Jill are working in the same lab and Jill appropriates
a paragraph word-for-word from a paper Jack is writing and pastes it in her own manuscript as her own
work.)
So if Jane should wish to publish her work, she must first ask Dr. Smith for the name and contact
information of the student author. Dr. Smith would then be ethically obligated to supply this
information to Jane so that Jane can fulfill her ethical obligations. Indeed, given that Dr. Smith is the
senior researcher in this scenario, he should from the outset reveal to Jane the origin of the work and
inform Jane of her ethical obligations--and his willingness to supply the name and contact information--
should she wish to publish.
Scenario #2: The paper is one that Dr. Smith was recently asked to review for a peer-reviewed
publication or an NIH application. He hasn’t turned in his review yet.
In this scenario, Dr. Smith has certainly committed moral turpitude by sharing the paper with
Jane without permission. Journal reviewers and NIH reviewers pledge confidentiality, at least because
the review process would be entirely unworkable if scientists couldn’t trust reviewers to honor the
identity of the work’s originators or feared that reviewers might steal the paper’s ideas and methods! 4
Smith’s knowledge of this paper along with Jane’s distress presents him with a conflict of loyalty. On the
one hand, he is duty bound to respect his confidentiality agreement with the journal or the NIH. On the
other hand, he feels a duty to help Jane with her research.
But by sharing the work with Jane, he not only violates that confidentiality agreement in
principle, he shows very poor practical judgment in failing to consider how Jane (as well as himself
perhaps) might eventually use the knowledge that obviously isn’t theirs. The Office of Research Integrity
asserts that “The theft or misappropriation of intellectual property includes the unauthorized use of
ideas or unique methods obtained by a privileged communication, such as a grant or manuscript
review.”2
 Thus, suppose Jane and Dr. Smith eventually submit a paper to a peer-reviewed journal or an
application to the NIH that describes the methods they’ll use but that does not acknowledge the source
or the originator of those methods. Notice, once they put forward work to the scientific community—as
in a paper submission or a grant—that derived from another’s work but that they nevertheless and
without authorization represent as theirs, they have committed plagiarism for which they can be
sanctioned severely.
And, unfortunately, that does happen. Alan Price published a paper in 2006 that reviewed 19
plagiarism cases that came to the Federal Office of Research Integrity’s attention.1
Price related one
case involving a professor of pathology “who copied almost all of a grant application on human DNA
telomerase enzyme … which had been given to him in confidence by a peer reviewer. The respondent
(i.e., the pathology professor accused of plagiarism) used it in his own NIH grant application.” 1, p.3

Another rather bizarre case involved a professor of chemistry who was accused by a former colleague
of plagiarizing the latter’s research design ideas from an NIH grant application into his own application.
Upon being accused, the alleged plagiarizer claimed that he had given the application to a postdoctoral
fellow as an academic exercise, and he had not realized that the fellow had actually plagiarized some of
the words from the application, which the alleged plagiarizer then—unknowingly he claimed—
incorporated into his own grant application. When asked to identify the post doctoral student, whose
protection was promised by both ORI and the University, the alleged plagiarizer refused.1, p. 2

What would be comical if the situation wasn’t so unfortunate (and sometimes career-ending) is
how such plagiarists fail to appreciate how their plagiarized work might fall into the very hands of the
person(s) from whom the work was plagiarized! But only a moment’s consideration is needed to be
impressed with that likelihood. Consider Jane’s case. She is working on a highly specialized project to
which only a handful of investigators around the world are devoting substantial effort. She finally finds
the solution to her problem, which doubtless has been generated by just such a specialist. When she
herself submits the work for review without an attribution to the originator of her methods, there is a
high likelihood that that very specialist will be asked to review her work (or eventually come across it)
and that he or she will instantly recognize it as their own. Indeed, of the 19 cases that Price reviewed in
his paper, 8 of them dealt solely with plagiarism. (The other 11 dealt with plagiarism in combination
with falsification or fabrication.) Price wrote that:
All but 1 of these 8 ORI cases of solely plagiarism involved the copying of words and/or ideas in
NIH grant applications, detected by a reviewer, who was in most cases the original applicant
whose own grant application to NIH (or to NSF), or the original author whose own publication,
had been plagiarized; they just happened to become a reviewer for NIH or NSF of the
questioned application and then reported the plagiarism to agency officials.1, p. 4
So, a point in this scenario is that while it is a serious lapse of professional integrity to breach a
confidentiality agreement and allow an unauthorized individual access to another’s confidentially
protected work, going the additional, morally unspeakable step of stealing that work and trying to pass
it off as one’s own might be easily discovered. Doing so combines theft with misrepresentation and can
blemish one’s career in a way from which he or she might never recover.
Scenario #3: The paper has been accepted for publication and will appear soon.
So, here, one might think that the moral thing for Dr. Smith to do would be to contact the author of the
paper and ask for permission to share the paper with Jane and allow her to replicate the experiment.
Once the author grants permission, then all things should proceed smoothly. If the author refuses, then
Jane must wait until the paper appears in print.
In fact, though, Dr. Smith needs to contact the journal editors first and secure their permission
for him to contact the author at least because 1) the journal owns the copyright to the material and
might wish to control its dissemination before it appears in wide circulation, and 2) the journal might
wish to keep Dr. Smith’s identity, as a reviewer, unknown to the author (and so refuse Dr. Smith’s
request). 4

Generally, if the journal has no problem with a request like Dr. Smith’s, an editor will contact the
author and inquire if he or she would entertain a request like Smith’s. The author might approve but
with stipulations—such that the paper can be read and discussed by members of a particular lab but not
disseminated to anyone else; or the author might stipulate that the paper can be read and discussed but 
none of the novel research methods described in the paper can be tried by anyone until the paper is
published. Or the author might deny the request altogether—perhaps because his institution wishes to
patent some of the paper’s intellectual work and the patent application process is taking longer than
expected. Interestingly, an author might be able to publish a paper and then patent its ideas later, but
doing so is tricky. Shamoo and Resnik note that:
If investors publish their ideas (or someone else does) prior to filing a patent, this may prevent
them from obtaining a patent on their inventions in most countries. However, the U.S. patent
laws have a one-year grace period from publication to patent. Thus, in the United States,
investors can publish first and patent later. However, they may submit a provisional patent
application with the U.S. Patent and Trade Office when they submit for publication, to protect
their proprietary interest before filing a patent. 3, p. 126
In conclusion, the temptation to use another scientist’s work product might be considerable and, based
on past history, certain persons will succumb to that temptation. The typical penalties handed down by
the NIH for plagiarism include the plagiarist’s having to certify through an institutional official that his or
her future grant applications and reports cite all sources appropriately; and/or the ORI can prohibit
plagiarists from serving on Public Health Service advisory committees, such as grant study sections for a
period of time (e.g., 2 to 10 years); or the plagiarist can be barred from receiving grants for a specific
period.1

One cannot fail to be impressed by how today’s investigators must not only be technically
scrupulous in their labs, but morally scrupulous as well. By sharing the manuscript with Jane, Dr. Smith
might be doing something morally unproblematic or he might be inviting disaster into his and Jane’s
careers. The devil is often in the details, but it will be the details or the circumstances of cases like these
that inform their moral status. "
"I once worked in a lab that conducted anti-aging research. The lab was operated by Dr. Smith,
who also owned and operated an assisted living facility nearby.
Dr. Smith was intrigued by homeopathic remedies that he thought might slow the aging
process and improve quality of life. His research centered on vitamin and nutritional
supplements, topical creams and salves, exercise programs and so on. Laboratory personnel
were constantly going to the assisted living facility and drawing blood, taking skin samples,
measuring bone density and respiratory capacity and the like.
I began feeling uncomfortable when I noticed that some of our research participants,
who had early senility or dementia and had little idea of what was going on, had their consent
to research participation signed by Dr. Smith. When I asked him about this, he looked a bit
anxious but told me that these individuals had signed over their power-of-attorney to him upon
entering the facility, and that he was therefore allowed to make decisions for them, including
research participation.
When we were informed that we were going to be visited by some representatives of a
grant foundation that might fund our work, Dr. Smith explicitly told us to say that we knew
nothing about how our various biological specimens were procured. He also told us to say that
our current research was on the cusp of success even though none of our assays had indicated
anything unique or exciting. He also made a point to remind all of us of the confidentiality and
nondisclosure stipulations in our employment contracts, which sounded like a veiled threat
should any of us discuss some of Smith’s problematic practices with the funding team or any
other outsiders.
We did not get the grant, and after a few months, I simply couldn’t tolerate the situation
any longer, and I left. Please comment.","""I once worked in a lab that conducted anti-aging research. The lab was operated by Dr. Smith,
who also owned and operated an assisted living facility nearby.
Dr. Smith was intrigued by homeopathic remedies that he thought might slow the aging
process and improve quality of life. His research centered on vitamin and nutritional
supplements, topical creams and salves, exercise programs and so on. Laboratory personnel
were constantly going to the assisted living facility and drawing blood, taking skin samples,
measuring bone density and respiratory capacity and the like.
I began feeling uncomfortable when I noticed that some of our research participants,
who had early senility or dementia and had little idea of what was going on, had their consent
to research participation signed by Dr. Smith. When I asked him about this, he looked a bit
anxious but told me that these individuals had signed over their power-of-attorney to him upon
entering the facility, and that he was therefore allowed to make decisions for them, including
research participation.
When we were informed that we were going to be visited by some representatives of a
grant foundation that might fund our work, Dr. Smith explicitly told us to say that we knew
nothing about how our various biological specimens were procured. He also told us to say that
our current research was on the cusp of success even though none of our assays had indicated
anything unique or exciting. He also made a point to remind all of us of the confidentiality and
nondisclosure stipulations in our employment contracts, which sounded like a veiled threat
should any of us discuss some of Smith’s problematic practices with the funding team or any
other outsiders.
We did not get the grant, and after a few months, I simply couldn’t tolerate the situation
any longer, and I left. Please comment."""
"I had decided to submit my first abstract ever for a neuroscience conference that I very much
wanted to attend. My research consisted of running human subjects through an fMRI scan so
as to collect brain activation data in response to simple visual stimuli. My data and analyses
appeared solid as the time drew near for me to write the abstract, so I was excited and eager to
proceed. My postdoc slowed me down, however, with a suggestion that I include a few more
subjects in the study. I agreed but voiced a concern that the submission deadline was coming
up. “Maybe you can use yourself in your study,” he said. “I mean, it’s only an abstract that
you’re submitting, and you can recruit more subjects between now and the conference and
make corrections accordingly.”
I was uneasy about using myself as a subject. I felt it was somehow unethical even
though I knew there was no way I could bias the results of the study due to the simplicity of the
paradigm I was using. Luckily, I was spared the problem: The next day my postdoc recruited
some subjects for the study so I avoided having to use myself. However, I still wonder what
would have happened if new subjects were not recruited. It was such a simple experiment that
I couldn’t have affected the results. But would recruiting myself be considered a conflict of
interest or be somehow unethical? ","In reflecting on this scenario, we were reminded of Hans Jonas’s famous essay “Philosophical
Reflections on Experimenting with Human Subjects,” which was originally published in 1969
and represented one of the early attempts to perform bioethical analysis from a secular rather
than religious or theological perspective.
According to that essay, Jonas would very much approve of our young investigator’s
self-recruitment. Jonas asserted that investigators themselves are ideal research participants
because:
If it is full, autonomous identification of the subject with the purpose that is required for
the dignifying of his serving as a subject—here it is; if strongest motivation—here it is; if
fullest understanding—here it is; if freest decision—here it is; if greatest integration
with the person’s total, chosen pursuit—here it is…By himself the scientist is free to
obey his obsession, to play his hunch, to wager on chance, to follow the lure of
ambition. It is all part of the “divine madness” that somehow animates the ceaseless
pressing against frontiers.
So, Jonas is arguing that nonmanipulation, motivation, and acute understanding of and
identification with the research goals are best exhibited by the investigators themselves.
Furthermore, if we worry about whether an individual’s participation in research is justified
given the risks, then the investigator’s passion and commitment to scientific discovery should
remove that anxiety and recommend his or her qualifications for participation in the strongest
terms possible. 
Complimenting Jonas’s argument, the history of scientific discovery is replete with
instances where investigators recruited themselves in their experiments. Perhaps the most
remarkable example is Barry Marshall, an Australian gastroenterologist who proved that most
stomach ulcers are caused by the bacterium Helicobacter pylori by drinking a solution that
contained the microbe in 1982.
 He and his colleague Robin Warren shared the Nobel Prize for
Medicine in 2005 in recognition of their discovery. After successful inoculation with monkeys,
Jonas Salk tested the polio vaccine on himself, his wife and his children. Werner Forssman was
awarded the 1956 Nobel Prize in medicine for his work on heart catheterization. He inserted a
catheter into his vein until it reached the right atrium of his heart and then took an X-ray of the
placement to prove it could work. Kevin Warwick, a British robotics researcher, implanted
electrodes in his body (and later in his wife’s) that could send signals to a robotic arm. His
discovery that impulses could be sent from the human nervous system to an artificial one
spurred the “transhumanist” movement, which is interested in the ethical use of electronic
augmentation or enhancement of the natural human body.
Unfortunately, not all such self-recruitment in scientific history ended as well as these.
In the early nineteenth century, Humphry Davy and Horace Wells became addicted to nitrous
oxide and chloroform respectively, as they investigated their anesthesiological properties.
(Davy’s chronic use incapacitated him for the last 20 years of his life, while Wells committed
suicide.)
 Daniel Alcides Carrion died in 1885 at the age of 28 when he had a friend inject him
with blood drawn from the wart of a 14-year old suffering from what was then called Oroya
fever. Carrion developed the disease and died. In his honor, Oroya fever—which was at
epidemic levels in Peru when Carrion studied it—was renamed Carrion Disease and the
Peruvian government recognizes October 5, the day of Carrion’s death, as Peruvian Medicine
Day.
And then there are Elizabeth Ascheim Woolf, Marie Curie and Rosalind Franklin who all
died of radiation exposure from their use of X-ray technology. Ascheim and her husband set up
for the first X-ray laboratory in San Francisco and experimented with the technology unaware
of its dangers.
Rosalind Franklin would surely have shared the Nobel Prize with Watson, Crick
and Wilkins in 1962 for the discovery of DNA. But Franklin died from ovarian cancer in 1958,
almost certainly as a result of her using X-ray crystallography to decipher the B form of the
helical structure of the DNA molecule.
Per the above scenario and pace Hans Jonas, contemporary ethics would probably
recommend a very conservative course as to whether or not an investigator should recruit him
or herself for an experiment. One fear is that if the investigator doesn’t suffer from the disease
being studied, he or she may feel a need to acquire it in order to test his or her hypothesis, as
Barry Marshall did. But an investigator’s intentionally introducing a disease into his or her body
can be strikingly antithetical to the utilitarian goal of achieving net utility. If the investigator
takes significant risks with his or her welfare, the promise of the research deliverable, i.e., the
end for which these efforts are being sought, is frankly imperiled. Had Jonas Salk’s injection of
the polio vaccine resulted in his being permanently incapacitated from the disease (or from
something related), the world would have to await another discoverer, which could have taken
years. One is reminded of the airline safety precaution to parents traveling with family if
oxygen in the cabin is discontinued: When the safety masks drop down, first place one on 
yourself and then help others. Inordinate altruism may result in a self-sacrifice that can
ultimately produce a significant net disutility.
Arguing from a deontological perspective, research participants largely serve as a means
to the end of hypothesis confirmation or the aggregation of beneficial, generalizable
knowledge. Nevertheless, we try to treat research participants as ends in themselves both
through the informed consent process as well as insisting on IRB protections, such that
participants are not subjected to more than minimal risk (save in exceptional cases that might
favorably and directly impact their welfare). Consequently, the investigator who first enrolls
himself in his own trial—which is a trial of 1, of course—before going through an IRB approval
process can be assuming too much risk and should be protected from his or her risky behavior.
Furthermore, and contrary to Jonas’s assertion that the investigator is the one best able
to give informed consent, one might argue that some researchers are so blinded by ambition or
the opportunity for prestige that they are unable to offer a truly voluntary and thoughtful
consent to participation in an experiment where the risks might be unreasonably high.
Of course and from a purely methodological perspective, an N of 1 is just that: a single
data point that can hardly count as generalizable knowledge. While some might find Salk’s
injecting himself with the polio vaccine admirable—less so, his injecting his wife and especially
less so his children—all it would have confirmed is that it was safe for him and his family but
possibly not safe for the family next door.
In the above scenario, however, safety does not appear to be a significant concern as
indicated by the millions of persons who have had MRIs without incident. We worry instead
about our young investigator’s participation from another angle: Might the findings on his
brain function be skewed by his familiarity with the research and its purpose?
On the one hand, if the investigator’s research goal is purely descriptive, i.e, motivated
by an interest in discerning the neural activation patterns of a particular visual stimulus such
that nothing beyond that descriptive aim is desired, then his participation is probably
acceptable. On the other hand, if a research hypothesis has been forwarded, e.g., “visual
stimuli of this or that sort will activate brain regions X, Y and Z,” then it might be the case that
the investigator’s foreknowledge of that hypothesis can bias his neural responses to the stimuli
in favor of the hypothesis.
This argument is hardly idle. Commentators discussing the substitution of fMRI for
polygraphy in lie detection have commented that the current state of the technology in no way
argues for such (assuming it even argues for the merits of polygraphy). Just as individuals have
learned to fool polygraphy, e.g., by biting their tongues or pressing their toes to the floor, they
might just as well fool an MRI by concentrating on feelings, thoughts or images that, with
enough know-how on their part, might produce findings that “prove” their testimony.
Consequently, it appears that we should be very cautious, even hesitant, about the idea
of researchers recruiting themselves for experiments. If the research posed minimal risks and
there is no compelling reason to think that the investigator could skew or bias his or her test
results in the direction of some research hypothesis, then his or her participation is probably
acceptable. If, however, the risks are considerable and/or a biased result from the
investigator’s participation is indeed possible, then that researcher’s participation would be
morally problematic and so should be disallowed. Ultimately, a researcher who enrolls him or
herself in an experiment before any other subjects are enrolled and especially before a 
sufficient amount of data collection among animals has occurred is acting rashly and is not
furthering the cause of science. 


"
"One of the oddest but most memorable experiences I ever had in my graduate and postgraduate training occurred one morning when I got to the lab rather early. Our lab was
a large one, and had recruited a number of fine, junior investigators from Southeast
Asia. As I hung up my coat, I glanced into an adjacent room and saw three of them
apparently praying over their experimental materials. They were standing around their
lab table. Their eyes were tightly shut, and they were obviously chanting a prayer, all
the while making circular arm movements with their palms outstretched over the
experiment. I quickly moved away, and I don’t think they saw me.
This may sound crazy but is that ethical? I mean, can you ethically argue that
researchers should not pray over their experiments because such activity might
heighten their interpretational biases or—and this is where things really get vague—
introduce some kind of “contaminating variable” into the experiment? I mean, there
have been research studies on the power of prayer in medicine with some studies
actually showing positive results.
I’ll never forget this provocative and rather touching experience. It posed such a
contrast, or maybe I should say a confluence, between deeply felt and applied
spirituality with the objective, scientific mindset of Western research. But should the
lab director condone this sort of thing as a regular practice? Do you think it poses any
cause for ethical or professional concern?","This scenario speaks to lab management issues in terms of personnel behaviors
affecting the work atmosphere, as well as to metaphysical issues that involve Western
notions of scientific realism, causality, and objectivity.
Why might many Western investigators feel uncomfortable about this scenario?
Paradoxically, if the traditional paradigm of Western science would categorically dismiss
the possibility of divine intervention affecting a lab experiment, then why shouldn’t we
simply allow the lab personnel to pray as they wish and leave them alone? On the other
hand, one might argue that the opportunity for a Hawthorne-like effect is present as the
lab personnel might improve the quality of their work with the adoption of some formal,
group prayer practice.
So, one response to the scenario might be that if such ritualistic
praying is allowed and it occurs, it should be duly documented in the laboratory
notebooks, described in any reports or manuscript submissions, and maintained in all
significant experimental moments (e.g., praying over the control as well as the
experimental arms of a project) since some might understand it as a significant
experimental variable.
Perhaps an equally concerning issue is whether or not the practice of group
prayer in the laboratory disturbs the objectivity of the praying investigators. Does it so
heighten or reinforce their expectation of or desire for a specific experimental result
that their objectivity might be compromised, such that they might be more subjectively
inclined to claim the confirmation of their hypothesis when others would disagree?
Might the prayerful have their objectivity disturbed as, for example, believing that their
data and their interpretation of the data are divinely blessed? Or might the prayerful be
requesting a divine favor such that their team be blessed in being the first in making the
great discovery, which certainly sounds like self-interested praying? But many, if not all,
investigators aim and hope for and perhaps even sometimes pray for a particular result.
The question of blemished or corrupted objectivity is probably best managed in the
traditional way: by reasonable oversight or peer review in the lab, such that solid
hypotheses are framed, and researchers discuss and justify their data gathering and
findings with their peers.
Should we be troubled by the prayerful investigators invoking some kind of
metaphysical intercession? Don’t clinicians occasionally pray with their patients,
especially the ones about to undergo surgeries and the like? We recently heard a story
about hospital staff who prepare the packages of surgical tools that are to be used in
their hospital’s operating rooms.
The names of patients are printed on the orders, and
some of the staff remarked that as they fill the order, they quietly say a prayer for each
and every patient’s recovery. Remarkably, one staff member admitted to performing
this prayer practice for over forty years.
Why does a story like this seem so heart-warming, while praying over a lab
experiment seems problematic? The answer is that clinical interventions do not
primarily involve a search for truth but seek to accommodate the self-interests of
patients (by way of relieving their suffering, curing their ills or diseases, etc.).
The practice of medicine would not exist without self-interested consumers, and it is
precisely those self-interests that medicine seeks to accommodate whenever possible.
The practice of research, however, is primarily and fundamentally motivated by an
interest in uncovering the truth. Its practice is fundamentally epistemological: to
confirm a hypothesis or create generalizable knowledge. Of course, that knowledge
might ultimately advance another’s self-interests, such as the patient who ultimately
benefits from a new, FDA approved antibiotic or antidepressant. But the anticipation of
relief from suffering and royalties to the drug’s discoverers must occupy a second place
to the investigator’s primary moral obligations of protecting research participants from
unnecessary or unreasonable harm and taking pains to insure the integrity of his or her
data.
How, then, might this phenomenon be managed? First of all, if a lab director
forbade such a practice, would he or she be infringing on the prayers’ freedom of
religious expression? Must the lab director make a “reasonable accommodation” for the
prayers, such as allowing them to pray in the very early morning? Probably not. Because
praying over an experiment is not a traditional or customary expression of religious
worship, one could assert that it is not a reasonable accommodation issue. It is hard to
imagine the prayers persuasively arguing that the only place they can pray is in a
laboratory, while it is easy to imagine that certain personnel praying in a laboratory
might significantly disturb the lab’s psychological or work atmosphere.
On the other hand, and especially depending on whether the laboratory is
located in a state or religiously affiliated institution, might other lab personnel not only
not be disturbed by the practice, but welcome it? If so, the lab director might want to
discern how the prayer practice is being perceived by other staff. How do they
understand the practice’s effect on the research being conducted and, especially, on
reporting experimental results? How does it affect other work being done? The lab
director must carefully ask him or herself “What exactly ought I be responding to here?”
(and, even then, be very thoughtful about how his or her own biases might affect the
answers).
Should the institution develop a policy on this? Does it matter, for example,
whether the experiment is federally or privately funded? Should these questions be
clarified by the institution’s office of legal affairs? Would it be acceptable for the
institution to leave the matter entirely up to the discretion of any of its lab directors,
such that they could categorically forbid the practice, or only allow it before or after the
lab’s customary hours of operation, or allow prayer to be practiced at any time?
Ultimately, this scenario recalls Horst Rittel’s and Melvin Webber’s 1973
discussion of the “wicked problem.”
Wicked problems are invariably multifactorial;
their very articulation is problematic as different persons will disagree on what the true
or real problem is; suggestions at resolving the problem only generate more problems;
no resolution seems more than tentative; and the core of the problem appears to
involve vague, ever-changing, or inconsistent phenomena.
There appears to be no decisive resolution to this scenario as different persons
will understand and weigh the questions and issues articulated above differently. The
idea of a ritual prayer practice over an experiment seems to challenge if not contradict
Western comprehensions of scientific method, but there is no way to prevent entirely
those who insist on its practice. The challenge is to evolve a management strategy in
the lab that is fair and respectful to the prayers, that respects the sensibilities of others,
and that does not compromise the integrity of research findings.

"